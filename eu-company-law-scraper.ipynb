{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urllib library used to query a website\n",
    "from urllib.request import urlopen\n",
    "# BeautifulSoup webscraping module for python\n",
    "from bs4 import BeautifulSoup\n",
    "# CSV parser\n",
    "import csv\n",
    "# Regular expressions\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import enchant\n",
    "import wordcloud\n",
    "us_d = enchant.Dict(\"en_US\")\n",
    "uk_d = enchant.Dict(\"en_GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process individual case given CELEX number\n",
    "def scrapeText(url):\n",
    "    print(\"Source: \" + str(url))\n",
    "    # Open the page\n",
    "    judgement_page = urlopen(url)\n",
    "    # Convert it to BeautifulSoup format \n",
    "    soup_judgement_page = BeautifulSoup(judgement_page, \"html.parser\")\n",
    "    return soup_judgement_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower() # lowercase\n",
    "    text_p = \"\".join([char for char in text if char not in string.punctuation]) # no punctuation\n",
    "    text_nonum = re.sub(r'\\d+', '', text_p) # no numbers\n",
    "    words = word_tokenize(text_nonum) # split into tokens (words)\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.append('article')\n",
    "    stop_words.append('eurlex')\n",
    "    filtered_words = [word for word in words if word not in stop_words] # remove english stopwords\n",
    "    tokens = []\n",
    "    for item in filtered_words: # remove all 1 and 2 character words\n",
    "        if (len(item) > 2):\n",
    "            tokens.append(item)\n",
    "    tokens_noduplicates = list(set(tokens)) # remove duplicates\n",
    "    pos = pos_tag(tokens_noduplicates) # postag text\n",
    "    dictionary_words = []\n",
    "    for item in tokens_noduplicates: # remove all non-dictionary words\n",
    "        if (uk_d.check(item) or us_d.check(item)):\n",
    "            dictionary_words.append(item)\n",
    "    return tokens, tokens_noduplicates, dictionary_words, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32019L2121&from=en\n"
     ]
    }
   ],
   "source": [
    "#parsed_page = scrapeText(\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex:32017L1132\")\n",
    "parsed_page = scrapeText(\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32019L2121&from=en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preprocess(parsed_page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "joined_words = \" \".join(result[0])+\" \"\n",
    "wordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = [], min_font_size = 10).generate(joined_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the WordCloud image                        \n",
    "# plt.figure(figsize = (8, 8), facecolor = None) \n",
    "# plt.imshow(wordcloud) \n",
    "# plt.axis(\"off\") \n",
    "# plt.tight_layout(pad = 0)   \n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "verbs = []\n",
    "adjectives = []\n",
    "adverbs = []\n",
    "all_terms = []\n",
    "\n",
    "for item in result[3]:\n",
    "    all_terms.append(item[0])\n",
    "    if ('NN' in item[1]):\n",
    "        nouns.append(item)\n",
    "    if ('VB' in item[1]):\n",
    "        verbs.append(item)\n",
    "    if ('JJ' in item[1]):\n",
    "        adjectives.append(item)\n",
    "    if ('RB' in item[1]):\n",
    "        adverbs.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(adverbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "import csv\n",
    "\n",
    "onto = get_ontology(\"https://raw.githubusercontent.com/MaastrichtU-IDS/cbcm-ontology/master/working_copy/eu-cm-ontology.owl\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://ids.maastrichtuniversity.nl/ontologies/cbm/eu-cm-ontology#AnnualAccount\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from re import finditer\n",
    "\n",
    "def camel_case_split(identifier):\n",
    "    matches = finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0) for m in matches]\n",
    "\n",
    "def process(entities):\n",
    "    newEntities = []\n",
    "    for e in entities:\n",
    "        if \"org.\" in str(e):\n",
    "            tmp = str(e).replace(\"org.\",\"\")\n",
    "            newEntities.extend(camel_case_split(tmp))\n",
    "        else:\n",
    "            tmp = str(e).replace(\"eu-cm-ontology.\",\"\")\n",
    "            newEntities.extend(camel_case_split(tmp))\n",
    "    return newEntities\n",
    "\n",
    "classes = process(list(onto.classes()))\n",
    "object_properties = process(list(onto.object_properties()))\n",
    "data_properties = process(list(onto.data_properties()))\n",
    "\n",
    "ont_entities = []\n",
    "ont_entities.extend(classes)\n",
    "ont_entities.extend(object_properties)\n",
    "ont_entities.extend(data_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kody.moodley\\.conda\\envs\\eu-company-law\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(ratio, list1, list2):\n",
    "    matches = {}\n",
    "    for item1 in list1:\n",
    "        current_matches = set()\n",
    "        for item2 in list2:\n",
    "            similarity = fuzz.ratio(item1, item2)\n",
    "            if (similarity <= 50):\n",
    "                current_matches.add(item2)\n",
    "        if (len(current_matches) > 0):\n",
    "            matches[item1] = list(current_matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_matches(90,all_terms,ont_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order': ['Border'],\n",
       " 'publication': ['Publication'],\n",
       " 'management': ['Management'],\n",
       " 'independent': ['Independent'],\n",
       " 'administration': ['Administration'],\n",
       " 'information': ['Information'],\n",
       " 'involve': ['involves'],\n",
       " 'mergers': ['merges'],\n",
       " 'resolution': ['Resolution'],\n",
       " 'transfers': ['transfers'],\n",
       " 'organisation': ['Organisation'],\n",
       " 'transfer': ['transfers'],\n",
       " 'formation': ['Information'],\n",
       " 'employment': ['Employment'],\n",
       " 'registered': ['Registered'],\n",
       " 'consultation': ['Consultation'],\n",
       " 'supervisory': ['Supervisory'],\n",
       " 'merging': ['Emerging'],\n",
       " 'conversion': ['Conversion'],\n",
       " 'merge': ['merges'],\n",
       " 'acquisition': ['Acquisition'],\n",
       " 'certificate': ['Certificate'],\n",
       " 'representation': ['Representation'],\n",
       " 'negotiation': ['Negotiation'],\n",
       " 'beneficial': ['Beneficial'],\n",
       " 'part': ['part'],\n",
       " 'transferred': ['Transferred']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
